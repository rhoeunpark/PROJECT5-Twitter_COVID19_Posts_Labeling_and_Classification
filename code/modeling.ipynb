{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60aeaac",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00e4b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.options.display.max_colwidth = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ec674b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70bdbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('../data/p_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99cb3e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32832, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09aae88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime       0\n",
       "p_text         0\n",
       "hashtag        0\n",
       "get_vaccine    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ba915",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb67363",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets['p_text']\n",
    "y = tweets['get_vaccine']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9acfef",
   "metadata": {},
   "source": [
    "## Baseline Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "012f5456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.509442\n",
      "1    0.490558\n",
      "Name: get_vaccine, dtype: float64\n",
      "0    0.509423\n",
      "1    0.490577\n",
      "Name: get_vaccine, dtype: float64\n",
      "0    0.509517\n",
      "1    0.490483\n",
      "Name: get_vaccine, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts(normalize=True))\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e477af",
   "metadata": {},
   "source": [
    "Baseline accuracy of about 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5afb828",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf613c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9317ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "new_stop_words = ['amp', \"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would']\n",
    "stopwords.extend(new_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa15727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(lowercase=True, \n",
    "                        preprocessor=None, \n",
    "                        tokenizer=LemmaTokenizer(), \n",
    "                        stop_words=stopwords, \n",
    "                        analyzer='word')\n",
    "\n",
    "X_train = tvec.fit_transform(X_train)\n",
    "X_test = tvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825bea5",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fffb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize classifiers\n",
    "classifiers = {\n",
    "    'logreg' : LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'svc' : SVC(random_state=42),\n",
    "    'random_forests' : RandomForestClassifier(random_state=42),\n",
    "    'multinomialNB' : MultinomialNB(),\n",
    "    'knearestneighbors' : KNeighborsClassifier(),\n",
    "    'adaboost' : AdaBoostClassifier(random_state=42, base_estimator=DecisionTreeClassifier()),\n",
    "    'xgboost' : XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9465824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(model, \n",
    "               X_train, y_train, X_test, y_test,\n",
    "               verbose=True):\n",
    "    \"\"\"\n",
    "    Fits a baseline model for each model specified.\n",
    "    Compiles accuracy, variance, precision and f1 score results in a dictionary.\n",
    "    For 2 classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "    \n",
    "    results['train_accuracy'] = accuracy_score(y_train, y_pred_train)\n",
    "    results['test_accuracy'] = accuracy_score(y_test, y_pred_test)\n",
    "    results['variance'] = results['train_accuracy'] - results['test_accuracy']\n",
    "    results['test_precision'] = precision_score(y_test, y_pred_test, pos_label=1, zero_division=0)\n",
    "    results['test_recall'] = recall_score(y_test, y_pred_test)\n",
    "    results['test_specificity'] = tn / (tn + fp)\n",
    "    results['test_f1'] = f1_score(y_test, y_pred_test, pos_label=1, zero_division=0)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35047546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(models, X_train, y_train, X_test, y_test, verbose=False):\n",
    "    \"\"\"\n",
    "    Returns the baseline model results in a dataframe.\n",
    "    For 2 classes.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        if verbose:\n",
    "            print('\\nRunning {} - {}'.format(name, model))\n",
    "        \n",
    "        results[name] = run_models(model, X_train, y_train, X_test, y_test, verbose=False)\n",
    "\n",
    "    return pd.DataFrame.from_dict(results, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aacaef64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>variance</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_specificity</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.845193</td>\n",
       "      <td>0.783158</td>\n",
       "      <td>0.062035</td>\n",
       "      <td>0.806133</td>\n",
       "      <td>0.734554</td>\n",
       "      <td>0.829946</td>\n",
       "      <td>0.768681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>0.955340</td>\n",
       "      <td>0.786204</td>\n",
       "      <td>0.169136</td>\n",
       "      <td>0.815123</td>\n",
       "      <td>0.729587</td>\n",
       "      <td>0.840705</td>\n",
       "      <td>0.769987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forests</th>\n",
       "      <td>0.987283</td>\n",
       "      <td>0.761687</td>\n",
       "      <td>0.225596</td>\n",
       "      <td>0.764199</td>\n",
       "      <td>0.743558</td>\n",
       "      <td>0.779139</td>\n",
       "      <td>0.753737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multinomialNB</th>\n",
       "      <td>0.842566</td>\n",
       "      <td>0.776001</td>\n",
       "      <td>0.066565</td>\n",
       "      <td>0.793034</td>\n",
       "      <td>0.735175</td>\n",
       "      <td>0.815302</td>\n",
       "      <td>0.763010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knearestneighbors</th>\n",
       "      <td>0.752065</td>\n",
       "      <td>0.599056</td>\n",
       "      <td>0.153010</td>\n",
       "      <td>0.583051</td>\n",
       "      <td>0.640795</td>\n",
       "      <td>0.558876</td>\n",
       "      <td>0.610561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.987283</td>\n",
       "      <td>0.693315</td>\n",
       "      <td>0.293968</td>\n",
       "      <td>0.659529</td>\n",
       "      <td>0.774604</td>\n",
       "      <td>0.615063</td>\n",
       "      <td>0.712450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.813288</td>\n",
       "      <td>0.754987</td>\n",
       "      <td>0.058301</td>\n",
       "      <td>0.790765</td>\n",
       "      <td>0.680534</td>\n",
       "      <td>0.826659</td>\n",
       "      <td>0.731520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   train_accuracy  test_accuracy  variance  test_precision  \\\n",
       "logreg                   0.845193       0.783158  0.062035        0.806133   \n",
       "svc                      0.955340       0.786204  0.169136        0.815123   \n",
       "random_forests           0.987283       0.761687  0.225596        0.764199   \n",
       "multinomialNB            0.842566       0.776001  0.066565        0.793034   \n",
       "knearestneighbors        0.752065       0.599056  0.153010        0.583051   \n",
       "adaboost                 0.987283       0.693315  0.293968        0.659529   \n",
       "xgboost                  0.813288       0.754987  0.058301        0.790765   \n",
       "\n",
       "                   test_recall  test_specificity   test_f1  \n",
       "logreg                0.734554          0.829946  0.768681  \n",
       "svc                   0.729587          0.840705  0.769987  \n",
       "random_forests        0.743558          0.779139  0.753737  \n",
       "multinomialNB         0.735175          0.815302  0.763010  \n",
       "knearestneighbors     0.640795          0.558876  0.610561  \n",
       "adaboost              0.774604          0.615063  0.712450  \n",
       "xgboost               0.680534          0.826659  0.731520  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results(classifiers,\n",
    "              X_train,\n",
    "              y_train,\n",
    "              X_test,\n",
    "              y_test\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb0cae3",
   "metadata": {},
   "source": [
    "For business purpose, it is more helpful to focus on optimize for the classification \"yes_vax\" population, who will be the potential users or customers. This narrows down to optimizing for the recall vs precision. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101de5e0",
   "metadata": {},
   "source": [
    "Recall vs precision tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cdb805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
